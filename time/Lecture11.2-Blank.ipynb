{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Work with Time\n",
    "## Lecture demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.graphics as smg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "from pandas import Series\n",
    "sns.set(style='white', color_codes=True, font_scale=1.3)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 6, 4\n",
    "\n",
    "# make the Pandas tables a little more readable\n",
    "from IPython.core.display import HTML\n",
    "css = open('style-table.css').read() + open('style-notebook.css').read()\n",
    "HTML('<style>{}</style>'.format(css))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read in stocks file\n",
    "# convert the string that corresponds to date into datetime\n",
    "# the first column (date) to be the index\n",
    "df_stock = pd.read_csv('stocks.csv',parse_dates=True,index_col=0)\n",
    "msft = df_stock.MSFT  # a series of MSFT stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapping up last lab..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# make a larger time series\n",
    "# give me 365 days staring at 1/1/2000\n",
    "rng = pd.period_range('1/1/2000',periods=365,freq='D')  \n",
    "ts = Series(np.random.randn(len(rng)),index=rng)\n",
    "ts.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create a new time series with the mean as the monthly value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# find max value in that month\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# working with data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_stock.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# B is telling pandas that we are working with business days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_stock[['AAPL','MSFT']]   # select apple and microsft\n",
    "# plot the time series\n",
    "df_stock[['AAPL','MSFT']].plot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# resample, replacing days by months, and use mean (average monthly value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "df_resam[['AAPL','MSFT']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can visualize the stock returns this year. (velocity)\n",
    "fig, ax = plt.subplots()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize the percentage change of percent change (acceleration)\n",
    "fig, ax = plt.subplots()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Resampling two ways - resample() is an aggregtation\n",
    "# asfreq() is selection\n",
    "print('On 12/30/2011, msft was at:', msft['2011-12-30'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# business year end frequency (select)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# business year end frequency (sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "msft.plot(alpha=0.5, style='-')\n",
    "msft.resample('BA').mean().plot(style=':')  \n",
    "msft.asfreq('BA').plot(style='--');\n",
    "plt.legend(['input', 'resample', 'asfreq'],\n",
    "           loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# give me the first 10 days of apple\n",
    "df_10day = df_stock.AAPL[:10]  \n",
    "df_10day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# give you the amount changed over time\n",
    "# does the right thing for weekends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# notice: skips the non-business days\n",
    "# does the right thing for weekends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# give me a resample (not restricted to business days)\n",
    "# can do this for frames too\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ffill in the missing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing with moving averages\n",
    "\n",
    "* Rolling - only take into account a window\n",
    "* Expanding - take into account everything before\n",
    "* Exponential Weighting - weight today more than yesterday\n",
    "  and yesterday more than day before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make play dataset\n",
    "rtest = pd.DataFrame(np.random.randn(600, 1), \n",
    "                  index = pd.date_range('7/1/2016', \n",
    "                                        freq = 'D', periods = 600), \n",
    "                  columns = ['A'])\n",
    "rtest['A'].plot(color='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# r.agg, r.apply, r.count, r.exclusions, r.max, r.median, r.name, r.quantile, \n",
    "# r.kurt, r.cov, r.corr, r.aggregate, r.std, r.skew, r.sum, r.var\n",
    "# consider 20 \"units\" back (days in this case)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# time series with a trend\n",
    "rtest = pd.DataFrame(np.random.randn(300)+np.arange(300)*.01, \n",
    "                  index = pd.date_range('7/1/2016', \n",
    "                                        freq = 'D', periods = 300), \n",
    "                  columns = ['A'])\n",
    "rtest['A'].plot(color='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# an expanding moving average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# exponential, com=.5 is how much decay\n",
    "# see http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.ewm.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do this for microsoft\n",
    "# WORKSHEET ACTIVITY\n",
    "# calculate the windows (rolling, expanding, exp)\n",
    "# describe what happens when you increase the value of com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Seasons + Auto-Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# correlation\n",
    "# generate 365 fake numbers\n",
    "d1 = np.random.random(365)\n",
    "# copy\n",
    "d2 = d1.copy()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(d1)\n",
    "plt.plot(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate the correlations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate xcorr (shifts one timeseries relative to the other)\n",
    "\n",
    "# calculate cross correlation between d1 and d2\n",
    "# maxlags --> how many lags should I try?  None --> all, 20 --> -20 to 20\n",
    "# normed --> normalize\n",
    "# lw = line width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# correlation\n",
    "d1 = np.random.random(365)    # generate 365 fake numbers\n",
    "d2 = d1.copy()                # copy\n",
    "for i in range(30):           # insert .2, 30 times at start of d3\n",
    "    d2 = np.insert(d2,0,0.2)\n",
    "d2 = d2[0:365]                # cut d2 so that it's back to 365 number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.plot(d1)\n",
    "plt.plot(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate the correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bad correlation due to shift\n",
    "# if we shift back we have a correlation of 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# what does this look like with xcorr?\n",
    "\n",
    "# calculate cross correlation between d1 and d2\n",
    "# maxlags --> how many lags should I try?  None --> all, 20 --> -20 to 20\n",
    "# normed --> normalize\n",
    "# lw = line width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Get Fancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_trend = pd.read_csv('googletrends.csv',parse_dates=True, index_col=0)\n",
    "df_trend = df_trend.to_period('W-SAT')  # convert so that times are based on periods of weeks ending on saturday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_trend.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grab all data from 2007 to 2013\n",
    "# grab the turkey and iphone time series\n",
    "# plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts_santa = df_trend.ix['2007':'2013','santa'].to_timestamp()\n",
    "ts_fifa = df_trend.ix['2007':'2013','FIFA'].to_timestamp()\n",
    "ts_beer = df_trend.ix['2007':'2013','beer'].to_timestamp()\n",
    "ts_iphone = df_trend.ix['2007':'2013','iphone'].to_timestamp()\n",
    "ts_turkey = df_trend.ix['2007':'2013','turkey'].to_timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_trend.ix['2007':'2013',['turkey','santa']].plot()\n",
    "# grabbing all data from 2007 to 2013\n",
    "# grabbing the turkey and iphone time series\n",
    "# plotting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#np.array(ts_santa.values)\n",
    "_ = plt.xcorr(ts_turkey.values.astype(float),ts_santa.values.astype(float),\n",
    "              usevlines=True,maxlags=None,normed=True,lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cross correlation between \"santa\" and \"turkey\"\n",
    "ccf = sm.tsa.stattools.ccf(ts_santa['2007':'2013'], ts_turkey['2007':'2013'])\n",
    "\n",
    "plt.plot(ccf)\n",
    "plt.xlim(0,300)\n",
    "plt.ylim(-0.5, 1)\n",
    "plt.axvline(4, linewidth=0.5)\n",
    "plt.axhline(0, color=\"black\", linewidth=1)\n",
    "plt.title('Cross Correlation: \"santa\" vs. \"turkey\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WORKSHEET QUESTION: what is this telling us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cross correlation between \"turkey\" and white noise\n",
    "white_noise = np.random.randn(len(ts_turkey))\n",
    "ccf = sm.tsa.stattools.ccf(ts_turkey, white_noise)\n",
    "\n",
    "plt.plot(ccf)\n",
    "plt.xlim(0,208)\n",
    "plt.ylim(-1,1)\n",
    "plt.axhline(0, color=\"black\", linewidth=0.75)\n",
    "plt.title('Cross Correlation: \"turkey\" vs. white noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## WORKSHEET QUESTION: find the cross correlation between beer and FIFA\n",
    "\n",
    "# what can we infer from this? what can't we?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocorrelation\n",
    "\n",
    "A measure of the correlation between the the timeseries with a lagged version of itself. For instance at lag 5, ACF would compare series at time instant ‘t1’…’t2’ with series at instant ‘t1-5’…’t2-5’ (t1-5 and t2 being end points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot autocorrelation function (ACF) of the data of \"turkey\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Zoom in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot ACF of an array of white noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial Autocorrelation\n",
    "\n",
    "Measures the correlation between the TS with a lagged version of itself but after eliminating the variations already explained by the intervening comparisons. Eg at lag 5, it will check the correlation but remove the effects already explained by lags 1 to 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Partial autocorrelation function of \"turkey\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot ACF of an array of white noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot ACF of \"iphone\".\n",
    "ts_iphone.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot ACF of \"iphone\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot PACF of \"iphone\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ^ grabbed the time series for turkey from 2007 to 2013\n",
    "\n",
    "# ^ decompose into seasonal and trend and residual data\n",
    "_ = decompose_result.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# WORKSHEET QUESTION: plot the decomposition for the iphone data\n",
    "# what do you see in the trend, what do you see in seasonal?\n",
    "\n",
    "# ^ grabbed the time series for turkey from 2007 to 2013\n",
    "\n",
    "# ^ decompose into seasonal and trend and residual data\n",
    "_ = decompose_result.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Rid of Trends - the easy way\n",
    "Sometimes we want to get rid of trends to get to stationary data or as part of more extensive analysis.\n",
    "\n",
    "Example: number of searches on google is going up (more users), but we don't actually care about that trends for detecting seasonality.  It's distracting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Detrend iphone with linear and quadratic trends respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the detrended results\n",
    "fig, ax = plt.subplots()\n",
    "df_iphone.plot(ax=ax)\n",
    "plt.title('detrending results of \"iphone\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction -- The simple variety\n",
    "\n",
    "If you assume your data is clean (stationary) - no trends, mean/variance constant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Given history sun activity, forecast the future activity\n",
    "df_sun_activity = sm.datasets.sunspots.load_pandas().data[['SUNACTIVITY']]\n",
    "df_sun_activity.index = pd.DatetimeIndex(start='1700', end='2009', freq='A')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "_ = df_sun_activity.ix['1950':].plot(ax=ax)\n",
    "\n",
    "\n",
    "plt.title('Sun Activity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Pipeline\n",
    "\n",
    "The long example - we don't have stationary data\n",
    "\n",
    "This is a common example on the Web, but a good explanation comes from: https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Grab passenger data\n",
    "passengers = pd.read_csv('AirPassengers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what's in our data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# are the data types right?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert to time series, and set to index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get num passengers in June, 1949\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get rows for 1949\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get total num passengers in 1949\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make it Stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's start by plotting the time series\n",
    "ts = passengers[\"#Passengers\"] \n",
    "plt.plot(ts)\n",
    "\n",
    "# notice we have both trend + season "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# create a couple of utility visualizations (we're going to use this a lot)\n",
    "def plotTS(timeseries):\n",
    "    rollmean = pd.rolling_mean(timeseries, window=12)\n",
    "    rollstd = pd.rolling_std(timeseries, window=12)\n",
    "    data = pd.DataFrame({'input': timeseries,\n",
    "                         'one-year rolling_mean': rollmean,\n",
    "                         'one-year rolling_std': rollstd})\n",
    "    ax = data.plot(style=['-', '--', ':'])\n",
    "    ax.lines[0].set_alpha(0.3)\n",
    "\n",
    "# utility method, we'll use this to figure out\n",
    "# if the timeseries is stationary\n",
    "def testDF(timeseries):\n",
    "    print('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print(dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the data and print the Dickey-Fuller stats\n",
    "plotTS(ts)\n",
    "testDF(ts)\n",
    "\n",
    "# this is telling us we are not stationary, test stat is not below\n",
    "# any of the critical values and p-value high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first thing, log transform the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first idea: remove trends\n",
    "# calcuate a rolling average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# subtract out the moving average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotTS(ts_log_moving_avg_diff)\n",
    "testDF(ts_log_moving_avg_diff)\n",
    "\n",
    "# better... test stat below 5% level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# maybe a better way is to not have a \n",
    "# strong window (fixed), use EWMA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# diff out the avg and plot/calc stats\n",
    "\n",
    "plotTS(ts_log_ewma_diff)\n",
    "testDF(ts_log_ewma_diff)\n",
    "# now we're below the 1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing seasonality - decompisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "#utility class, same as the plot function before, but\n",
    "# we want to grab out the values\n",
    "def plotDecom(timeseries):\n",
    "    decomposition = seasonal_decompose(timeseries)\n",
    "\n",
    "    trend = decomposition.trend\n",
    "    seasonal = decomposition.seasonal\n",
    "    residual = decomposition.resid\n",
    "    plt.subplot(411)\n",
    "    plt.plot(ts_log, label='Original')\n",
    "    plt.legend(loc='best')\n",
    "    plt.subplot(412)\n",
    "    plt.plot(trend, label='Trend')\n",
    "    plt.legend(loc='best')\n",
    "    plt.subplot(413)\n",
    "    plt.plot(seasonal,label='Seasonality')\n",
    "    plt.legend(loc='best')\n",
    "    plt.subplot(414)\n",
    "    plt.plot(residual, label='Residuals')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    return residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot and find the residual for the ts_log data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts_log_decompose = residual\n",
    "ts_log_decompose.dropna(inplace=True)\n",
    "plotTS(ts_log_decompose)\n",
    "testDF(ts_log_decompose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differencing\n",
    "\n",
    "Another way to get rid of trend and seasonality, subtract out the last value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotTS(ts_log_diff)\n",
    "testDF(ts_log_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting\n",
    "\n",
    "Auto-Regressive Integrated Moving Averages (ARIMA)\n",
    "\n",
    "(p,d,q) of the ARIMA model:\n",
    "\n",
    "* Number of AR (Auto-Regressive) terms (p): AR terms are just lags of dependent variable. For instance if p is 5, the predictors for x(t) will be x(t-1)….x(t-5).\n",
    "* Number of MA (Moving Average) terms (q): MA terms are lagged forecast errors in prediction equation. For instance if q is 5, the predictors for x(t) will be e(t-1)….e(t-5) where e(i) is the difference between the moving average at ith instant and actual value.\n",
    "* Number of Differences (d): These are the number of nonseasonal differences, i.e. in this case we took the first order difference. So either we can pass that variable and put d=0 or pass the original variable and put d=1. Both will generate same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ACF and PACF plots:\n",
    "from statsmodels.tsa.stattools import acf, pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# q – The lag value where the ACF chart crosses the upper confidence \n",
    "# interval for the first time. In this case q=2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# The lag value where the PACF chart crosses the upper \n",
    "# confidence interval for the first time. In this case p=2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AR Model \n",
    "\n",
    "(ignore the MA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# p,d,q\n",
    "\n",
    "plt.plot(ts_log_diff)\n",
    "plt.plot(results_AR.fittedvalues, color='red')\n",
    "plt.title('RSS: %.4f'% sum((results_AR.fittedvalues-ts_log_diff)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MA Model \n",
    "\n",
    "(ignore the AR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(ts_log_diff)\n",
    "plt.plot(results_MA.fittedvalues, color='red')\n",
    "plt.title('RSS: %.4f'% sum((results_MA.fittedvalues-ts_log_diff)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(ts_log_diff)\n",
    "plt.plot(results_ARIMA.fittedvalues, color='red')\n",
    "plt.title('RSS: %.4f'% sum((results_ARIMA.fittedvalues-ts_log_diff)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# put the predictions back into same scale\n",
    "\n",
    "predictions_ARIMA_diff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predictions given as difference to last prediction\n",
    "# cummulative sum will let us recover this\n",
    "\n",
    "predictions_ARIMA_diff_cumsum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add to the first value in the original TS\n",
    "\n",
    "predictions_ARIMA_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(ts)\n",
    "plt.plot(predictions_ARIMA)\n",
    "plt.title('RMSE: %.4f'% np.sqrt(sum((predictions_ARIMA-ts)**2)/len(ts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WORKSHEET EXERCISE: if we have time, see if you can\n",
    "# run this for one of the trend datasets (iphones, turkeys, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
